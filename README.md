
 ğŸ­ Sentiment Analysis on IMDB Movie Reviews

This project demonstrates how to build a Sentiment Analysis model that can classify IMDB movie reviews as Positive or Negative. It combines NLP preprocessing techniques with Machine Learning (Logistic Regression) to achieve a solid baseline for text classification tasks.

ğŸ“Œ Project Overview

Movie reviews are a great source of unstructured data that reflect human opinions. The goal of this project is to:

Clean and preprocess raw text reviews.
Convert the text into meaningful numerical features using TF-IDF Vectorization.
Train a Logistic Regression model for binary sentiment classification.
Evaluate model performance with metrics like accuracy, confusion matrix, and classification report.
Test the trained model on new, unseen reviews.

ğŸ§¹ Data Preprocessing

To prepare text for modeling, the following steps are applied:

Remove HTML tags and special characters.
Convert text to lowercase.
Remove stopwords (e.g., â€œtheâ€, â€œisâ€, â€œandâ€).
Tokenize and normalize the words.
Generate a cleaned_review column.
This reduces noise and ensures the model focuses on meaningful words.

ğŸ” Feature Engineering

TF-IDF Vectorizer: Converts text into numerical feature vectors.
Limited to 5000 features to balance performance and accuracy.
Output: A sparse matrix representation of reviews.

ğŸ¤– Model Training

Algorithm: Logistic Regression (liblinear solver).
Reason: Simple, interpretable, and effective for binary classification tasks.
Split: 75% Training, 25% Testing.

ğŸ“Š Model Evaluation

The model was evaluated using:
Accuracy Score
Confusion Matrix
Classification Report (Precision, Recall, F1-score)

âœ”ï¸ Accuracy achieved: ~0.88 â€“ 0.90 (depending on the random split).

ğŸ§ª Testing on New Reviews

The trained model can predict unseen reviews:
Positive example: â€œThis movie was fantastic with great acting!â€ â†’ âœ… Positive
Negative example: â€œWaste of time. Poor script and boring characters.â€ â†’ âŒ Negative
Neutral example: â€œIt was okay, nothing special.â€ â†’ Prediction depends on wording.

ğŸ“¦ Saving & Reusing the Model

The trained model and vectorizer can be saved using Joblib:

joblib.dump(log_reg, 'logistic_regression_model.pkl')
joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')


This allows future predictions without retraining.

ğŸš€ Future Improvements

Experiment with advanced models (e.g., SVM, Random Forest, or Deep Learning with LSTMs/BERT).
Perform hyperparameter tuning.
Expand dataset with more diverse reviews.
Build a simple Flask/Django API to deploy the model as a web app.
